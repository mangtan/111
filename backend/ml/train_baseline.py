"""
Train a simple GradientBoostingRegressor on generated samples.
Input CSV must contain feature columns and label 'y'.
"""
from __future__ import annotations

import argparse
import os
import json
import joblib
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, mean_absolute_error
from sklearn.ensemble import GradientBoostingRegressor


FEATURES = [
    'vn_kv', 'length_km', 'max_i_ka',
    'deg_from', 'deg_to',
    'base_violations', 'base_max_loading_percent', 'base_total_losses_mw'
]


def main():
    parser = argparse.ArgumentParser(description='Train GBDT baseline on generated samples.')
    parser.add_argument('--data', type=str, required=True, help='CSV file generated by ml.generate_dataset')
    parser.add_argument('--model', type=str, default='data/ml/gbdt_ieee14.joblib', help='output model path')
    parser.add_argument('--seed', type=int, default=42)
    args = parser.parse_args()

    df = pd.read_csv(args.data)
    y = df['y'].values
    # Minimal feature set; drop id-ish columns
    X = df[FEATURES].values

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=args.seed)

    model = GradientBoostingRegressor(random_state=args.seed)
    model.fit(X_train, y_train)

    pred = model.predict(X_test)
    r2 = r2_score(y_test, pred)
    mae = mean_absolute_error(y_test, pred)

    os.makedirs(os.path.dirname(args.model), exist_ok=True)
    joblib.dump({'model': model, 'features': FEATURES}, args.model)

    print(json.dumps({'r2': r2, 'mae': mae, 'n_train': len(X_train), 'n_test': len(X_test)}, indent=2))


if __name__ == '__main__':
    main()

